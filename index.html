<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Panayiotis Charalambous</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/cmu/style.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  
  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v1.2.1
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">
      <div class="profile">
        <div id="flock_container" style="margin: 0px;border: 0ch;z-index: -1000; position:fixed"></div>
        <h1 class="text-light text-center" style="margin-top: 4cm;">
          <a href="index.html">Panayiotis Charalambous</a>
          <img src="assets/img/profile-panayiotis.jpg" alt="" class="img-fluid rounded-circle">
        </h1>
        <div class="hero-container " data-aos="fade-in" >
          <p>
            <h6 class="text-light text-center">
              <span class="typed"  data-typed-items="Researcher, Developer, Team Leader, Husband, Father"></span>
          </h6>
        </p>
      </div>
      
        <div class="social-links mt-3 text-center">
          <a href="mailto:p.charalambous@cyens.org.cy" class="email"><i class="bx bx-envelope"></i></a>
          <a href="https://www.linkedin.com/in/panayiotis-charalambous-b9b9b410/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://www.facebook.com/panayiotis.charalambous.7" class="facebook"><i class="bx bxl-facebook"></i></a>
          <a href="https://scholar.google.com/citations?user=w1v8d2YAAAAJ" class="google"><i class="bx bxl-google"></i></a>
        </div>
      </div>

      <nav class="nav-menu">
        <ul>
          <li class="active"><a href="index.html"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="#bio"><i class="bx bx-user"></i> <span>Short Bio</span></a></li>
          <li><a href="#resume"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="#projects"><i class="bx bxs-quote-alt-left"></i> Projects</a></li>
          <li><a href="#publications"><i class="bx bx-book-content"></i> Publications</a></li>
          <li><a href="#contact"><i class="bx bx-envelope"></i> Contact</a></li>
        </ul>
      </nav><!-- .nav-menu -->

      <div class="container  text-light" style="font-size: small;margin-bottom: 10px;vertical-align: text-bottom;">
        <div class="credits">
          <div class="copyright">
            &copy; Copyright <strong><span>Panayiotis Charalambous 2020</span></strong>
          </div> 
            <!-- All the links in the footer should remain intact.-->
          <!-- You can delete the links only if you purchased the pro version. -->
          <!-- Licensing information: https://bootstrapmade.com/license/ -->
          <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
          Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
        </div>
      </div>

      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <!-- <section id="hero" class="d-flex flex-column justify-content-center align-items-center">
    <div class="hero-container" data-aos="fade-in">
      <h1>Panayiotis Charalambous</h1>
      <p>> <span class="typed" data-typed-items="Researcher, Developer, Team Leader, Husband, Father"></span></p>
    </div>
  </section> -->
  
  <!-- End Hero -->

  <main id="main">
    <!-- ======= About Section ======= -->
    <section id="bio" class="about">
      <div class="container">
    
        <div class="section-title">
          <h2>Bio</h2>
        </div>

        <div class="row">
          <div class="col-lg-3" data-aos="fade-right">
            <img src="assets/img/profile-img.jpg" class="img-fluid" alt="">
          </div>
          <div class="col-lg-9 pt-4 pt-lg-0 content" data-aos="fade-left">
            <!-- <h3>Research Team Leader &amp; Geek</h3> -->
				<p>Hello, my name is Panayiotis Charalambous and I am a Research Assistant Professor and team leader of the <a href="https://veupnea.github.io">V-EUPNEA: Living, Breathing Virtual Worlds</a> group at the <a href="https://cyens.org.cy">CYENS Centre of Excellence</a>. I am also a Research Fellow at The Cyprus Institute. I was educated at the National and Kapodistrian University of Athens, Greece (BSc and MSc) and have a PhD from the University of Cyprus. Previously I worked as a Visiting Lecturer in the Department of Computer Science at the University of Cyprus and as an Associate Research Scientist and a Computational Scientist at the CaSToRC centre of the Cyprus Institute. Between 2014-2016 I was a post-doctoral fellow at INRIA Rennes, France under the supervision of Dr. Julien Pettre where I worked on the development of novel algorithms for the authoring and simulation of human crowds. I coordinate and work on several projects funded by Horizon 2020, RPF/RIF and other agencies. I am a member of the ACM and the Eurographics association and has served in the program committee of several conferences and is a reviewer of several prestigious journals and conferences. My research interests include Computer Animation, Virtual Humans, Crowd Simulation, Digital Cultural Heritage and Real-Time Technologies for Digital Twins and Filming. 
        </p>
            <!-- <div class="row">
              <div class="col-lg-6">
                <ul>
                  <li><i class="icofont-rounded-right"></i> <strong>Birthday:</strong> 1 May 1995</li>
                  <li><i class="icofont-rounded-right"></i> <strong>Website:</strong> www.example.com</li>
                  <li><i class="icofont-rounded-right"></i> <strong>Phone:</strong> +123 456 7890</li>
                  <li><i class="icofont-rounded-right"></i> <strong>City:</strong> City : New York, USA</li>
                </ul>
              </div>
              <div class="col-lg-6">
                <ul>
                  <li><i class="icofont-rounded-right"></i> <strong>Age:</strong> 30</li>
                  <li><i class="icofont-rounded-right"></i> <strong>Degree:</strong> Master</li>
                  <li><i class="icofont-rounded-right"></i> <strong>PhEmailone:</strong> email@example.com</li>
                  <li><i class="icofont-rounded-right"></i> <strong>Freelance:</strong> Available</li>
                </ul>
              </div> -->
            </div>
          </div>
        </div>

      </div>
    </section><!-- End About Section -->

  
    <!-- ======= Resume Section ======= -->
    <section id="resume" class="resume">
      <div class="container">

        <div class="section-title">
          <h2>Resume</h2>
          <a href="panayiotis.CV.2020.04.pdf">Download CV</a>
          <!-- <p>I'm currently doing research on Computer Animation at <a href="https:/rise.org.cy">RISE</a> where I lead the <a href="http://eupnea.rise.org.cy">V-EUPNEA: Living, Breathing Virtual Worlds research group</a>.</p> -->
        </div>

    </section><!-- End Resume Section -->

    <!-- ======= Publications Section ======= -->
    <section id="publications" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Publications</h2>
          <p>Here are some recent publications.For a complete list of publications, please visit my <a href="https://scholar.google.com/citations?user=w1v8d2YAAAAJ&hl=en">Google Scholar page</a>.</p>
        </div>

        <div class="row" data-aos="fade-up">
          <div class="col-lg-12 d-flex justify-content-center">
            <ul id="portfolio-flters">
              <li data-filter="*" class="filter-active">All</li>
              <li data-filter=".filter-journal">Journals</li>
              <li data-filter=".filter-conf">Conferences</li>
              <li data-filter=".filter-book">Book Chapters</li>
            </ul>
          </div>
        </div>

        <div class="row portfolio-container" data-aos="fade-up" data-aos-delay="100">
          <div class="portfolio-item * filter-conf publistYear">
            2021
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="vrst2021perceived" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/vrst2021perceived.jpg" alt="..." class="img-fluid img-rounded center-block" title="vrst2021perceived teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/vrst2021perceived.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Perceived realism of pedestrian crowds trajectories in VR.
                </h2>
                <span class="publistAuthors">
                  Daniele Giunchi, Riccardo Bovo, Panayiotis Charalambous, Fotis Liarokapis, Alastair Shipman, Stuart James, Anthony Steed, Thomas Heinis.
                </span>
                <br>
                <span class="publistJournal">
                  Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology (VRST'21), 2021. 
                </span>
                <p id="vrst2021-abstract" class="abstract">
                  Crowd simulation algorithms play an essential role in populating Virtual Reality (VR) environments with multiple autonomous humanoid agents. The generation of plausible  trajectories can be a significant computational cost for real-time graphics engines, especially in untethered and mobile devices such as portable VR devices. Previous research explores the plausibility and realism of crowd simulations on desktop computers but fails to account the impact it has on immersion. This study explores how the realism of crowd trajectories affects the perceived immersion in VR. We do so by running a psychophysical experiment in which participants rate the realism of real/synthetic trajectories data, showing similar level of perceived realism.
                </p>
                <div class="pubLinks">
                  <a href="publications/vrst2021-perceived.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3489849.3489860">
                    <img src="assets/img/acm-logo1-150x150.png" width=32 version" title="Publication Version">
                  </a>
                  <a href="https://youtu.be/95Sw2RKOn18">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Publication Video">
                  </a>
                  <a href="https://youtu.be/-pukX0VBxLo">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="VRST 2021 Presentation Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->


          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="cog2021towards" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/cog2021towards.jpg" alt="..." class="img-fluid img-rounded center-block" title="vrst2021perceived teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/cog2021towards.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Towards a multi-agent non-player character road network: a Reinforcement Learning approach.
                </h2>
                <span class="publistAuthors">
                  Stela Makri and Panayiotis Charalambous.
                </span>
                <br>
                <span class="publistJournal">
                  2021 IEEE Conference on Games (CoG). 
                </span>
                <p id="cog2021-abstract" class="abstract">
                  Creating detailed and interactive game environments is an area of great importance in the video game industry. This includes creating realistic Non-Player Characters which respond seamlessly to the players actions. Machine learning had great contributions to the area, overcoming scalability and robustness shortcomings of hand-scripted models. We introduce the early results of a reinforcement learning approach in building a simulation environment for heterogeneous, multi-agent non-player characters in a dynamic road network game scene.
                </p>
                <div class="pubLinks">
                  <a href="publications/cog2021-towards.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://doi.org/10.1109/CoG52621.2021.9619047">
                    <img src="assets/img/ieee_logo.png" height=32 version" title="Publication Version">
                  </a>
                  <a href="https://youtu.be/-qwFddCkyDo">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Publication Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="cog2021emotion" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/cog2021emotion.jpg" alt="..." class="img-fluid img-rounded center-block" title="vrst2021perceived teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/cog2021emotion.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Emotion Recognition from 3D Motion Capture Data using Deep CNNs.
                </h2>
                <span class="publistAuthors">
                  Haris Zacharatos, Christos Gatzoulis, Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                  2021 IEEE Conference on Games (CoG). 
                </span>
                <p id="cog2021-abstract" class="abstract">
                  Designing computer games requires a player-centered approach. Whilst following guidelines and functional requirement specifications is part of the process, observing and measuring qualities of the players experience is key in providing feedback to game designers. Moreover, it can also be used to create adaptive and personalized experiences for players. With the advancement of affective computing and gaming user
                  interfaces, the opportunity to recognize the player's emotions becomes more feasible and each different modality can offer additional information as affect expression is less defined as compared to action selection. This paper explores the use of 3D skeleton motion data transformed to 2D images that encode pose and movement dynamics to represent annotated emotions. The 2D images are then used to train and test the Inception V3 CNN model on a binary classification emotion recognition between happy and sad emotions. Preliminary results in unseen
                  test data indicate that the above transformation technique can capture emotional information. The paper also discusses future directions that may improve the effectiveness of the proposed method on a wider scale.
                </p>
                <div class="pubLinks">
                  <a href="publications/cog2021-emotion.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://doi.org/10.1109/CoG52621.2021.9619065">
                    <img src="assets/img/ieee_logo.png" height=32 version" title="Publication Version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->
          
          <div class="portfolio-item * filter-conf publistYear">
            2020
          </div>
          
          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="gch2020digital" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/gch2020digital.jpg" alt="..." class="img-fluid img-rounded center-block" title="gch2020digital teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/gch2020digital.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Digital Layered Models of Architecture and Mural Paintings over Time.
                </h2>
                <span class="publistAuthors">
                  Milagros Guardia, Paola Pogliani, Giulia Bordi, Panayiotis Charalambous, Carlos Andujar,Xavier Pueyo.
                </span>
                <br>
                <span class="publistJournal">
                  Eurographics Workshop on Graphics and Cultural Heritage (GCH), 2020. 
                </span>
                <p id="gch2020-abstract" class="abstract">
                  The European project Enhancement of Heritage Experiences: The Middle Ages. Digital Layered Models of Architecture and Mural Paintings over Time (EHEM), approved in the call for JPICH Conservation, Protection and Use (0127) in the year 2020, aims to obtain virtual reconstructions of medieval artistic heritage - architecture with mural paintings - that are as close as possible to the original at different times, incorporating historical-artistic knowledge and the diachronic perspective of heritage, as an instrument for researchers, restorers and heritage curators and to improve the visitor's perceptions and experiences.
                </p>
                <div class="pubLinks">
                  <a href="publications/gch2020-digital.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="publications/gch2020-digital-poster.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="Final Poster">
                  </a>
                  <a href="http://diglib.eg.org/handle/10.2312/gch20201295">
                    <img src="assets/img/icon-eg.png" width=32 version" title="Publication Version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->


          <div class="portfolio-item * filter-conf filter-journal publistYear">
            2019
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="mig19why" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/mig2019-poster.jpg" alt="..." class="img-fluid img-rounded center-block" title="vhcie18virtual teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/mig2019-poster.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Why did the human cross the Road?
                </h2>
                <span class="publistAuthors">
                  Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                  Motion, Interaction and Games (MIG ’19). Association for Computing Machinery, New York, NY, USA, Article 47, 1–2.
                  <a href="http://www.mig2019.website/" style="color:crimson;">Best Poster Award</a>
                </span>
                <p id="cgf2014-abstract" class="abstract">
                  Humans at rest tend to stay at rest. Humans in motion tend to cross the road – Isaac Newton.” Even though this response is meant to be a joke to indicate the answer is quite obvious, this important feature of real world crowds is rarely considered in simulations. Answering this question involves several things such as how agents balance between reaching goals, avoid collisions with heterogeneous entities and how the environment is being modeled. As part of a preliminary study, we introduce a reinforcement learning framework to train pedestrians to cross streets with bidirectional traffic. Our initial results indicate that by using a very simple goal centric representation of agent state and a simple reward function, we can simulate interesting behaviors such as pedestrians crossing the road through crossings or waiting for cars to pass.
                </p>
                <div class="pubLinks">
                  <a href="publications/mig2019-why.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="publications/mig2019-why-poster.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="Final Poster">
                  </a>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3359566.3364696">
                    <img src="assets/img/acm-logo1.png" width=32 version" title="Publisher Website">
                  </a>
                  <a href="https://youtu.be/H3jtQ5H8uvM">
                    <img src="assets/img/icon-youtube.png" width=32 version" title="Publication Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal">
            <div id="ijepr2019immersive" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/ijepr2019immersive.jpg" alt="..." class="img-fluid img-rounded center-block" title="ijepr2019immersive teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/ijepr2019immersive.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Immersive Computing and Crowd Simulation Techniques in Modelling Urban Commons: The Case of Nicosia-Cyprus
                </h2>
                <span class="publistAuthors">
                    Georgios Artopoulos, Panayiotis Charalambous and Colter Eugene Wehmeier.
                </span>
                <br>
                <span class="publistJournal">
                  International Journal of E-Planning Research (IJEPR), Vol 8, Issue 1, pp. 35-49. 2019.
                </span>
                <p id="ijepr2019immersive-abstract" class="abstract">
                  This article reports on the technical development and testing of the basic components of a virtual environment platform that could be used for the cross-disciplinary study of complex urban realities, such as the historic city of Nicosia, Cyprus - the last divided capital of Europe. This platform captures data of virtual visitors' movements in space, and the article suggests that these data could help better understand the impact of planning scenarios and design interventions in open public spaces that used to be popular among the citizens of the historic city. The article presents how this platform uses interaction and immersion opportunities to engage citizens and stakeholders in the management of public open spaces that are associated with built heritage. Crowd simulation is discussed as a computational technique that when is combined with the presented virtual environment platform, and under the right conditions, would contribute to a digital practice for small-scale urban modelling. However, it is beyond the scope of this technical note to provide a full empirical testing and validation of the presented immersive virtual environment.
                </p>
                <div class="pubLinks">
                  <!-- <a href="publications/j">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a> -->
                  <a href="https://www.igi-global.com/gateway/article/217706">
                    <img src="assets/img/ici-global.png" height=32  version" title="Publisher version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <div class="portfolio-item * filter-conf publistYear">
            2018
          </div>


          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal">
            <div id="sc18enabling" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/sc2018-enabling.jpg" alt="..." class="img-fluid img-rounded center-block" title="sc18enabling teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/sc2018-enabling.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Enabling virtual collaboration in Digital Cultural Heritage in the SEEM region.
                </h2>
                <span class="publistAuthors">
                  Panayiotis Charalambous, Georgios Artopoulos.
                </span>
                <br>
                <span class="publistJournal">
                  Scalable Computing: Practice and Experience. Vol. 19, Issue 2, pp. 161-174. (2018).
                </span>
                <p id="icat2018-abstract" class="abstract">
                  It has been observed that many researchers in the humanities do not use digital tools to their full extent for their research. Some of the most pressing needs of researchers in Digital Cultural Heritage (DCH) are data storage and handling and large scale computing. Linking these researchers to experienced groups will significantly improve productivity and research innovation in DCH. This work presents our efforts in enabling virtual collaboration for research in the South East and Eastern Mediterranean region and more specifically the deployment of the Clowder CMS system and the development of extraction services to handle, manage and automatically process DCH data. We give technical descriptions of the system and provide some results and discussions of our efforts to enable virtual collaboration between regional level DCH researchers in the context of the Horizon 2020 funded VI-SEEM project.
                </p>
                <div class="pubLinks">
                  <a href="publications/sc2018-enabling.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://www.scpe.org/index.php/scpe/article/view/1348">
                    <img src="assets/img/icon-sc.png" width=32  version" title="Publisher version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->
          

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="icat18analysis" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/icat2018analysis.jpg" alt="..." class="img-fluid img-rounded center-block" title="icat18analysis teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/icat2018analysis.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Analysis of Spatio-temporal Data in Virtual Historic Spaces.
                </h2>
                <span class="publistAuthors">
                  Georgios Artopoulos, Panayiotis Charalambous.
                </span>
                <br>
                <span class="publistJournal">
                  International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments (ICAT-EGVE) 2018. 
                </span>
                <p id="icat2018-abstract" class="abstract">
                  This paper presents a virtual reality workflow for citizen engagement in the management of neglected historic sites in contested cities, such as Nicosia, Cyprus, the last divided capital of Europe. It is contextualized in an ongoing research for the use of interactive visualization technologies for co-creation and co-management design practices in public space management. We demonstrate initial results from tracking the movement and gaze of users in VR walkthroughs of a historic site with and without user driven interventions and discuss on future directions.
                </p>
                <div class="pubLinks">
                  <a href="publications/icat2018-analysis.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://diglib.eg.org/handle/10.2312/egve20181308">
                    <img src="assets/img/icon-eg.png" width=32 version" title="author-prepared version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->
          
          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="vhcie18virtual" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/vhcie2018-nn-navigation.jpg" alt="..." class="img-fluid img-rounded center-block" title="vhcie18virtual teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/vhcie2018-nn-navigation.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Virtual Environment Navigation Assisted by Neural Networks.
                </h2>
                <span class="publistAuthors">
                  Georgios Kyrlitsias, Amyr Borges Fortes Neto, Panayiotis Charalambous, Marios Avraamides and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                  Virtual Humans and Crowds for Immersive Environments (VHCIE '18).
                </span>
                <p id="cgf2014-abstract" class="abstract">
                  Applications using Virtual Environments (VE) are becoming increasingly popular due to greater computational capacity and improvements in graphics processing units and tracking devices. As a result, much research has been carried out on various aspects of VEs, including the input devices that can be used to navigate scenes when physical movement is not permitted. Here, we test whether implementing a neural network to assist users avoid collisions with virtual obstacles, can benefit the navigation experience. Our hypothesis was that users with no gaming experience in particular, would appreciate the assistance of the neural network in navigation. However, our pilot data suggest the exact opposite: participants with video game experience liked the assisted navigation more than participants with no video game experience.
                </p>
                <div class="pubLinks">
                  <a href="publications/vhcie2018-NNNavigation.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <div class="portfolio-item * filter-book filter-journal publistYear">
            2016
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-book">
            <div id="hc16simulating" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/2016.HeterogeneousCrowds-199x300.jpg" alt="..." class="img-fluid img-rounded center-block" title="hc16simulating teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/2016.HeterogeneousCrowds-199x300.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Simulating Heterogeneous Crowds with Interactive Behaviors.
                </h2>
                <span class="publistAuthors">
                  Edited by: Nuria Pelechano, Jan M. Allbeck, Mubbasir Kapadia, Norman I. Badler.
                </span>
                <br>
                <span class="publistJournal">
                  Simulating Heterogeneous Crowds with Interactive Behaviors. CRC Press.
                </span>
                <p id="hc2016-abstract" class="abstract">
                  I had the privilege of co-authoring two book chapters with Yiorgos Chrysanthou on Data-Driven Crowd simulation and evaluation. More specifically, we wrote Chapter 3: Learning Heterogeneous Crowd Behavior from the Real World and Chapter 10: Data-Driven Crowd Evaluation. 
                </p>
                <div class="pubLinks">
                  <a href="https://www.crcpress.com/Simulating-Heterogeneous-Crowds-with-Interactive-Behaviors/Pelechano-Allbeck-Kapadia-Badler/p/book/9781498730365">
                    <img src="assets/img/CRC-Logo-150x150.jpg" width=32 version" title="author-prepared version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal">
            <div id="cgf2016group" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/cgf2016-groups.jpg" alt="..." class="img-fluid img-rounded center-block" title="cgf2014pag teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/cgf2016-groups.png" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="https://youtu.be/878tiKCXW-M" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Group Modeling: A Unified Velocity-Based Approach.
                </h2>
                <span class="publistAuthors">
                    Zhiquo Ren, Panayiotis Charalambous, Julien Bruneau, Qunsheng Peng and Julien Pettré.
                </span>
                <br>
                <span class="publistJournal">
                    Computer Graphics Forum, vol. 36, pp. 45-56. 2016. (Presented at Eurographics 2017)
                </span>
                <p id="cgf2016group-abstract" class="abstract">
                  Crowd simulators are commonly used to populate movie or game scenes in the entertainment industry. Even though it is crucial to consider the presence of groups for the believability of a virtual crowd, most crowd simulations only take into account individual characters or a limited set of group behaviors. We introduce a unified solution that allows for simulations of crowds that have diverse group properties such as social groups, marches, tourists and guides, etc. We extend the Velocity Obstacle approach for agent‐based crowd simulations by introducing Velocity Connection; the set of velocities that keep agents moving together while avoiding collisions and achieving goals. We demonstrate our approach to be robust, controllable, and able to cover a large set of group behaviors.
                </p>
                <div class="pubLinks">
                  <a href="publications/cgf2016-Groups.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="publications/cgf2016-Groups-Appendix.pdf">
                    <img src="assets/img/icon-pdf3-appendix.png" width=32 version" title="Appendix">
                  </a>
                  <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12993">
                    <img src="assets/img/icon-eg.png" width=32  version" title="Publisher version">
                  </a>
                  <a href="https://youtu.be/878tiKCXW-M">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <div class="portfolio-item * filter-conf filter-journal publistYear">
            2015
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal filter-conf">
            <div id="cgf2015emotion" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/cgf2015-lma.jpg" alt="..." class="img-fluid img-rounded center-block" title="cgf2015emotion teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/cgf2015-lma.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="https://youtu.be/DoVP-80vTHA" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Emotion Analysis and Classification: Understanding the Performers' Emotions Using the LMA Entities.
                </h2>
                <span class="publistAuthors">
                    Andreas Aristidou, Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                    Computer Graphics Forum, vol. 34, pp. 262-276. 2015. (Presented at Eurographics 2016)
                </span>
                <p id="cgf2016group-abstract" class="abstract">
                  The increasing availability of large motion databases, in addition to advancements in motion synthesis, has made motion indexing and classification essential for better motion composition. However, in order to achieve good connectivity in motion graphs, it is important to understand human behaviour; human movement though is complex and difficult to completely describe. In this paper, we investigate the similarities between various emotional states with regards to the arousal and valence of the Russell's circumplex model. We use a variety of features that encode, in addition to the raw geometry, stylistic characteristics of motion based on Laban Movement Analysis (LMA). Motion capture data from acted dance performances were used for training and classification purposes. The experimental results show that the proposed features can partially extract the LMA components, providing a representative space for indexing and classification of dance movements with regards to the emotion. This work contributes to the understanding of human behaviour and actions, providing insights on how people express emotional states using their body, while the proposed features can be used as complement to the standard motion similarity, synthesis and classification methods.
                </p>
                <div class="pubLinks">
                  <a href="publications/cgf2015-lma.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12598">
                    <img src="assets/img/icon-eg.png" width=32  version" title="Publisher version">
                  </a>
                  <a href="https://youtu.be/DoVP-80vTHA">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                  </a>
                  <a href="https://vidape.cs.ucy.ac.cy/">
                    <img src="assets/img/icon-project-150x150.png" width=32  version" title="Youtube Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->
          
          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="mig2015crowdart" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/mig2015-crowdart2.jpg" alt="..." class="img-fluid img-rounded center-block" title="mig2015crowdart teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/mig2015-crowdart2.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="https://youtu.be/TUCr7zBRxOM" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>
                <!-- Text and Links for publication -->
                <div class="col-sm-10 text-justify">
                  <h2 class="publistTitle">
                    Crowd Art: Density and Flow Based Crowd Motion Design.
                  </h2>
                  <span class="publistAuthors">
                      Kevin Jordao, Panayiotis Charalambous, Marc Christie, Julien Pettré and Marie Paul-Cani.
                  </span>
                  <br>
                  <span class="publistJournal">
                    MIG '15: Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games.
                  </span>
                  <p id="mig2015crowdart" class="abstract">
                    Artists, animation and game designers are in demand for solutions to easily populate large virtual environments with crowds that satisfy desired visual features. This paper presents a method to intuitively populate virtual environments by specifying two key features: localized density, being the amount of agents per unit of surface, and localized flow, being the direction in which agents move through a unit of surface. The technique we propose is also time-independant, meaning that whatever the time in the animation, the resulting crowd satisfies both features. To achieve this, our approach relies on the Crowd Patches model. After discretizing the environment into regular patches and creating a graph that links these patches, an iterative optimization process computes the local changes to apply on each patch (increasing/reducing the number of agents in each patch, updating the directions of agents in the patch) in order to satisfy overall density and flow constraints. A specific stage is then introduced after each iteration to avoid the creation of local loops by using a global pathfinding process. As a result, the method has the capacity of generating large realistic crowds in minutes that endlessly satisfy both user specified densities and flow directions, and is robust to contradictory inputs. At last, to ease the design the method is implemented in an artist-driven tool through a painting interface.
                  </p>
                  <div class="pubLinks">
                    <a href="publications/mig2015-crowdart.pdf">
                      <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                    </a>
                    <a href="https://youtu.be/TUCr7zBRxOM">
                      <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                    </a>
                    <a href="http://dl.acm.org/citation.cfm?doid=2822013.2822023">
                      <img src="assets/img/acm-logo1-150x150.png" width=32  version" title="Publisher version">
                    </a>
                  </div>
                </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal">
            <div id="jocch2015folk" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/jocch2015-folk.jpg" alt="..." class="img-fluid img-rounded center-block" title="jocch2015folk teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/jocch2015-folk.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Folk Dance Evaluation Using Laban Movement Analysis.
                </h2>
                <span class="publistAuthors">
                  Andreas Aristidou, Efstathios Stavrakis, Panayiotis Charalambous, Yiorgos Chrysanthou, and Stephania Loizidou Himona. 
                </span>
                <br>
                <span class="publistJournal">
                  ACM Journal on Computing and Cultural Heritage. Vol. 8, Issue 4, Article 20 (August 2015).
                </span>
                <p id="jocch2015folka" class="abstract">
                  Motion capture (mocap) technology is an efficient method for digitizing art performances, and is becoming increasingly popular in the preservation and dissemination of dance performances. Although technically the captured data can be of very high quality, dancing allows stylistic variations and improvisations that cannot be easily identified. The majority of motion analysis algorithms are based on ad-hoc quantitative metrics, thus do not usually provide insights on style qualities of a performance. In this work, we present a framework based on the principles of Laban Movement Analysis (LMA) that aims to identify style qualities in dance motions. The proposed algorithm uses a feature space that aims to capture the four LMA components (Body, Effort, Shape, Space), and can be subsequently used for motion comparison and evaluation. We have designed and implemented a prototype virtual reality simulator for teaching folk dances in which users can preview dance segments performed by a 3D avatar and repeat them. The user’s movements are captured and compared to the folk dance template motions; then, intuitive feedback is provided to the user based on the LMA components. The results demonstrate the effectiveness of our system, opening new horizons for automatic motion and dance evaluation processes.
                </p>
                <div class="pubLinks">
                  <a href="publications/jocch2015-folk.pdf.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="https://dl.acm.org/citation.cfm?id=2755566">
                    <img src="assets/img/acm-logo1-150x150.png" width=32  version" title="Publisher version">
                  </a>
                  <a href="https://vidape.cs.ucy.ac.cy/">
                    <img src="assets/img/icon-project-150x150.png" width=32  version" title="Youtube Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <div class="portfolio-item * filter-journal filter-conf publistYear">
            2014
          </div>
          
          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal">
            <div id="cgf2014pag" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/cgf2014-pag.jpg" alt="..." class="img-fluid img-rounded center-block" title="cgf2014pag teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/cgf2014-pag.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="http://youtu.be/QaEQpXDspvo" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>

                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  The PAG Crowd: A Graph Based Approach for Efficient Data‐Driven Crowd Simulation.
                </h2>
                <span class="publistAuthors">
                    Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                    Computer Graphics Forum, vol. 33, no. 8, pp. 95-108. 2014.
                </span>
                <p id="cgf2014-abstract" class="abstract">
                      We present a data‐driven method for the real‐time synthesis of believable steering behaviours for virtual crowds. The proposed method interlinks the input examples into a structure we call the perception‐action graph (PAG) which can be used at run‐time to efficiently synthesize believable virtual crowds. A virtual character's state is encoded using a temporal representation, the Temporal Perception Pattern (TPP). The graph nodes store groups of similar TPPs whereas edges connecting the nodes store actions (trajectories) that were partially responsible for the transformation between the TPPs. The proposed method is being tested on various scenarios using different input data and compared against a nearest neighbours approach which is commonly employed in other data‐driven crowd simulation systems. The results show up to an order of magnitude speed‐up with similar or better simulation quality.
                </p>
                <div class="pubLinks">
                  <a href="publications/cgf2014-pag.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="http://onlinelibrary.wiley.com/doi/10.1111/cgf.12403/abstract">
                    <img src="assets/img/icon-eg.png" width=32  version" title="Publisher version">
                  </a>
                  <a href="http://www.cs.ucy.ac.cy/~totis/papers/cgf2014-pag.html">
                    <img src="assets/img/icon-project.png" width=32  version" title="Project website">
                  </a>
                  <a href="http://youtu.be/QaEQpXDspvo">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-journal filter-conf">
            <div id="pg2014pda" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/pg2014-pda2.jpg" alt="..." class="img-fluid img-rounded center-block" title="pg2014pda teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/pg2014-pda2.jpg" data-gall="portfolioGallery" class="venobox" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="http://youtu.be/NlgClnGPit4" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>

                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  A Data‐Driven Framework for Visual Crowd Analysis.
                </h2>
                <span class="publistAuthors">
                  Panayiotis Charalambous, Ioannis Karamouzas, Stephen J. Guy, and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                    Computer Graphics Forum, vol. 33, no. 7, pp. 41-50. 2014. (Presented at Pacific Graphics 2014).
                </span>
                <p class="abstract">
                  We present a novel approach for analyzing the quality of multi-agent crowd simulation algorithms. Our approach is data-driven, taking as input a set of user-defined metrics and reference training data, either synthetic or from video footage of real crowds. Given a simulation, we formulate the crowd analysis problem as an anomaly detection problem and exploit state-of-the-art outlier detection algorithms to address it. To that end, we introduce a new framework for the visual analysis of crowd simulations. Our framework allows us to capture potentially erroneous behaviors on a per-agent basis either by automatically detecting outliers based on individual evaluation metrics or by accounting for multiple evaluation criteria in a principled fashion using Principle Component Analysis and the notion of Pareto Optimality. We discuss optimizations necessary to allow real-time performance on large datasets and demonstrate the applicability of our framework through the analysis of simulations created by several widely-used methods, including a simulation from a commercial game.
                </p>
                <div class="pubLinks">
                  <a href="publications/pg2014-evaluation.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                  <a href="http://onlinelibrary.wiley.com/doi/10.1111/cgf.12472/abstract">
                    <img src="assets/img/icon-eg.png" width=32  version" title="Publisher version">
                  </a>
                  <a href="http://www.cs.ucy.ac.cy/~totis/papers/pg2014.html">
                    <img src="assets/img/icon-project.png" width=32  version" title="Project website">
                  </a>
                  <a href="http://youtu.be/NlgClnGPit4">
                    <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->


          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="mig2014optimization" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/mig2014-patches.jpg" alt="..." class="img-fluid img-rounded center-block" title="mig2014optimization teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/mig2014-patches.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <a href="https://youtu.be/Zlqvp6et9cU" data-gall="portfolioGallery" class="venobox vbox-item" title="Video" data-vbtype="video" >
                        <i class="bx bx-video"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>
                <!-- Text and Links for publication -->
                <div class="col-sm-10 text-justify">
                  <h2 class="publistTitle">
                    Optimization-based computation of locomotion trajectories for crowd patches.
                  </h2>
                  <span class="publistAuthors">
                    Jose Guillermo Rangel Ramirez, Devin Lange, Panayiotis Charalambous, Claudia Esteves, and Julien Pettré.
                  </span>
                  <br>
                  <span class="publistJournal">
                    In Proceedings of the Seventh International Conference on Motion in Games (MIG '14). ACM, New York, NY, USA, 7-16.
                  </span>
                  <p id="mig2015crowdart" class="abstract">
                    Over the past few years, simulating crowds in virtual environments has become an important tool to give life to virtual scenes; be it movies, games, training applications, etc. An important part of crowd simulation is the way that people move from one place to another. This paper concentrates on improving the crowd patches approach proposed by Yersin et al. [Yersin et al. 2009] that aims on efficiently animating ambient crowds in a scene. This method is based on the construction of animation blocks (called patches) concatenated together under some constraints to create larger and richer animations with limited run-time cost. Specifically, an optimization based approach to generate smooth collision free trajectories for crowd patches is proposed. The contributions of this work to the crowd patches framework are threefold; firstly a method to match the end points of trajectories based on the Gale-Shapley algorithm [Gale and Shapley 1962] is proposed that takes into account preferred velocities and space coverage, secondly an improved algorithm for collision avoidance is proposed that gives natural appearance to trajectories and finally a cubic spline approach is used to smooth out generated trajectories. We demonstrate several examples of patches and how they were improved by the proposed method, some limitations and directions for future improvements.
                  </p>
                  <div class="pubLinks">
                    <a href="publications/mig2014-trajectories1.pdf">
                      <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                    </a>
                    <a href="https://youtu.be/Zlqvp6et9cU">
                      <img src="assets/img/icon-youtube.png" width=32  version" title="Youtube Video">
                    </a>
                    <a href="http://onlinelibrary.wiley.com/doi/10.1111/cgf.12472/abstract">
                      <img src="assets/img/acm-logo1-150x150.png" width=32  version" title="Publisher version">
                    </a>
                  </div>
                </div>
            </div>
          </div>
          <!-- End of Publication -->

          <div class="portfolio-item * filter-conf publistYear">
            2012
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="euromed2012reconstruction" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/euromed2012-nicosia.jpg" alt="..." class="img-fluid img-rounded center-block" title="mig2014optimization teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/euromed2012-nicosia.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                    </div>
                </div>
                <!-- Text and Links for publication -->
                <div class="col-sm-10 text-justify">
                  <h2 class="publistTitle">
                    Reconstruction of everyday life in 19th century nicosia.
                  </h2>
                  <span class="publistAuthors">
                    Panayiotis Charalambous, Hesperia Iliadou, Charalambos Apostolou, and Yiorgos Chrysanthou.
                  </span>
                  <br>
                  <span class="publistJournal">
                    In Proceedings of the 4th international conference on Progress in Cultural Heritage Preservation (EuroMed'12), Marinos Ioannides, Dieter Fritsch, Johanna Leissner, Rob Davies, and Fabio Remondino (Eds.). Springer-Verlag, Berlin, Heidelberg, 568-577. 
                  </span>
                  <p id="mig2015crowdart" class="abstract">
                    This paper presents the first stages of a larger project concerning the study and realization of a 3D interactive environment of everyday life in 19th century Nicosia. The presented study involves the recreation of the built urban environment (i.e. the architecture of the city) based on historic and archival information taken from the first Land Registry documentations taking place on the island at the end of the Ottoman era by British engineers.
                  </p>
                  <div class="pubLinks">
                    <a href="publications/euromed-2012.pdf.pdf">
                      <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                    </a>
                    <a href="http://link.springer.com/chapter/10.1007%2F978-3-642-34234-9_58">
                      <img src="assets/img/icon-springer.png" width=32  version" title="Publisher Version">
                    </a>
                    <a href="http://reconlife.cs.ucy.ac.cy/">
                      <img src="assets/img/icon-project.png" width=32  version" title="Project Website">
                    </a>
                  </div>
                </div>
            </div>
          </div>
          <!-- End of Publication -->

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="eauh2012reviving" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/eauh2012-nicosia.jpg" alt="..." class="img-fluid img-rounded center-block" title="mig2014optimization teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/eauh2012-nicosia.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                    </div>
                </div>
                <!-- Text and Links for publication -->
                <div class="col-sm-10 text-justify">
                  <h2 class="publistTitle">
                    Reviving Nicosia of the XIXth Century.
                  </h2>
                  <span class="publistAuthors">
                    Hesperia Iliadou, Panayiotis Charalambous and Yiorgos Chrysanthou.
                  </span>
                  <br>
                  <span class="publistJournal">
                    EAUH 2012, Prague, Czech Republic.
                  </span>
                  <p id="mig2015crowdart" class="abstract">
                    In this paper we describe our on-going work on the virtual reconstruction and population of XIXth Century Nicosia. The project involves the development of a semi-automatic pipeline that will take as input maps and land-registry deeds and will give as a result a 3D model of the urban space inhabited by animated virtual characters, guided by the historic information. The aim is to present a unique insight to the everyday life of a bygone era. In the city, now divided by a wall into Muslim north and Christian south, a population of Muslims coexisted with the Christian-Orthodox population as well as with other minorities, in an interesting intertwine of culture and religion located in the dense built environment within the city walls.
                  </p>
                  <div class="pubLinks">
                    <a href="publications/EAUH-2012.pdf">
                      <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                    </a>
                    <a href="http://reconlife.cs.ucy.ac.cy/">
                      <img src="assets/img/icon-project.png" width=32  version" title="Project Website">
                    </a>
                  </div>
                </div>
            </div>
          </div>
          <!-- End of Publication -->
          
          
          <div class="portfolio-item * filter-conf publistYear">
            2010
          </div>

          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="mig2010learning" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                    <img src="publications/img/mig2010.jpg" alt="..." class="img-fluid img-rounded center-block" title="mig2010learning teaser" class="abstract">
                    <div class="portfolio-links">
                      <a href="publications/img/mig2010.jpg" data-gall="portfolioGallery" class="venobox vbox-item" title="Large Image">
                        <i class="bx bx-zoom-in"></i>
                      </a>
                      <!-- <a href="portfolio-details.html" title="More Details"><i class="bx bx-link"></i></a> -->
                    </div>
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Learning Crowd Steering Behaviors from Examples
                </h2>
                <span class="publistAuthors">
                  Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                  Motion in Games 2010.
                </span>
                <p class="abstract">
                  Crowd steering algorithms generally use empirically selected stimuli to determine when and how an agent should react. These stimuli consist of information from the environment that potentially influence behavior such as an agent’s visual perception, its neighboring agents state and actions, locations of nearby obstacles, etc. The various different approaches, rule-based, example-based or other, all define their responses by taking into account these particular sensory inputs.
                  In our latest experiments we aim to determine which of a set of sensory inputs affect an agent’s behavior and at what level. Using videos of real and simulated crowds, the steering behavior (i.e. trajectories) of the people are tracked and time sampled. At each sample, the surrounding stimuli of each person and their actions are recorded. These samples are then used as the input of a regression algorithm that learns a function that can map new input states (stimuli) to new output values (speed, direction). A series of different simulations are conducted with different time varying stimuli each time in order to extract all the necessary information.
                  Identifying the most important factors that affect good steering behaviors can help in the design of better rule based or example based simulation systems. In addition they can help improve crowd evaluation methods.
                </p>
                <div class="pubLinks">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-642-16958-8_4">
                    <img src="assets/img/icon-springer-150x150.png" width=32 version" title="author-prepared version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->


          <!-- Start of Publication -->
          <div class="portfolio-item filter-conf">
            <div id="pg2014pda" class="row publistItem fade-up " >
              <!-- Teaser image-->
                <div class="col-sm-2 portfolio-wrap">
                </div>

              <!-- Text and Links for publication -->
              <div class="col-sm-10 text-justify">
                <h2 class="publistTitle">
                  Learning Crowd Behavior.
                </h2>
                <span class="publistAuthors">
                  Panayiotis Charalambous and Yiorgos Chrysanthou.
                </span>
                <br>
                <span class="publistJournal">
                  Workshop on Crowd Simulation (co-located with CASA 2010).
                </span>
                <p class="abstract">
                  We present here our ongoing work on learn-ing crowd behavior. The steering behavior of crowds from various video sources is tracked and databases of examples are gener-ated. These examples contain various stimuli (metrics) that could affect the persons behavior. These databases are used to learn rules for crowd steering in an agent based framework using re-gression algorithms and more specifically, decision trees. Various simulations are run and the statistics measured at the simulation stage are compared to those of the original video to de-termine which stimuli affect an agents behavior the most.
                </p>
                <div class="pubLinks">
                  <a href="publications/casa2010learning.pdf">
                    <img src="assets/img/icon-pdf3.png" width=32 version" title="author-prepared version">
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- End of Publication -->

      </div>      


    </section>
    
    <!-- ======= End of Publications Section ======= -->


    <!-- ======= Contact Section ======= -->
    <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <h2>Contact</h2>
          <p></p>
        </div>

        <div class="row" data-aos="fade-in">

          <div class="col-lg-5 d-flex align-items-stretch">
            <div class="info">
              <div class="address">
                <i class="icofont-google-map"></i>
                <h4>Location:</h4>
                <p>Tryfon Building, Eleftheria Square, Konstantinou Palaiologou 1, Nicosia 1011, Cyprus</p>
              </div>

              <div class="email">
                <i class="icofont-envelope"></i>
                <h4>Email:</h4>
                <p>p.charalambous@cyens.org.cy</p>
              </div>

              <!-- <div class="phone">
                <i class="icofont-phone"></i>
                <h4>Call:</h4>
                <p>+1 5589 55488 55s</p>
              </div> -->

			  <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3261.4681725718788!2d33.35895481524487!3d35.16988208031677!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x14de178afeaccd75%3A0x2fd81c1f5a798a9!2sRISE!5e0!3m2!1sen!2slu!4v1587732710728!5m2!1sen!2slu"  frameborder="0" style="border:0; width: 100%; height: 290px;" allowfullscreen></iframe>

            </div>

          </div>

          <!-- <div class="col-lg-7 mt-5 mt-lg-0 d-flex align-items-stretch">
            <form action="forms/contact.php" method="post" role="form" class="php-email-form">
              <div class="form-row">
                <div class="form-group col-md-6">
                  <label for="name">Your Name</label>
                  <input type="text" name="name" class="form-control" id="name" data-rule="minlen:4" data-msg="Please enter at least 4 chars" />
                  <div class="validate"></div>
                </div>
                <div class="form-group col-md-6">
                  <label for="name">Your Email</label>
                  <input type="email" class="form-control" name="email" id="email" data-rule="email" data-msg="Please enter a valid email" />
                  <div class="validate"></div>
                </div>
              </div>
              <div class="form-group">
                <label for="name">Subject</label>
                <input type="text" class="form-control" name="subject" id="subject" data-rule="minlen:4" data-msg="Please enter at least 8 chars of subject" />
                <div class="validate"></div>
              </div>
              <div class="form-group">
                <label for="name">Message</label>
                <textarea class="form-control" name="message" rows="10" data-rule="required" data-msg="Please write something for us"></textarea>
                <div class="validate"></div>
              </div>
              <div class="mb-3">
                <div class="loading">Loading</div>
                <div class="error-message"></div>
                <div class="sent-message">Your message has been sent. Thank you!</div>
              </div>
              <div class="text-center"><button type="submit">Send Message</button></div>
            </form>
          </div>
 -->
        </div>

      </div>
    </section><!-- End Contact Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <!-- <footer id="footer">
    <div class="container">
      <div class="credits">
        <div class="copyright">
          &copy; Copyright <strong><span>Panayiotis Charalambous 2020</span></strong>
        </div>  -->
          <!-- All the links in the footer should remain intact.-->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        <!-- Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer> -->
  <!-- End  Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/p5/p5.min.js"></script>
  <!-- <script src="assets/vendor/particles.js/particles.min.js"></script> -->

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>
  <script src="assets/js/flock.js"></script>
  <!-- <script stc="assets/js/particles.js"></script> -->


</body>

</html>